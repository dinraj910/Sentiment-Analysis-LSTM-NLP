# -*- coding: utf-8 -*-
"""sentiment_lstm_kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xwGpvaM7insuUwsEQszLKn0bWIimsoBG

# Sentiment Analysis using LSTM (Kaggle Dataset)

This notebook builds a **resume-grade sentiment analysis system** using:
- Raw text data (CSV)
- Word-level tokenization
- Padding & masking
- Trainable embeddings
- LSTM (Many-to-One)
- TensorFlow / Keras

The trained model is saved for deployment using Streamlit.

1. IMPORTS & CONFIGURATION
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import pickle

# Reproducibility
tf.random.set_seed(42)
np.random.seed(42)

# Configuration (LOCKED)
VOCAB_SIZE = 20000
MAX_LEN = 200
EMBED_DIM = 128
LSTM_UNITS = 128
BATCH_SIZE = 32
EPOCHS = 5

"""UPLOAD & LOAD DATASET"""

# Load dataset
df = pd.read_csv("/content/sentiment_data.csv")
df.head()

"""DATA INSPECTION & NORMALIZATION"""

df.info()

df.head(10)

"""Handle column name differences"""

# Try to infer text and label columns automatically
text_col = None
label_col = None

for col in df.columns:
    if "text" in col.lower() or "review" in col.lower():
        text_col = col
    if "sentiment" in col.lower() or "label" in col.lower():
        label_col = col

print("Text column:", text_col)
print("Label column:", label_col)

"""Clean & map labels"""

text_col = 'Comment'
df = df[[text_col, label_col]].dropna()

df[label_col].value_counts()

# Normalize labels to binary
df[label_col] = df[label_col].map({
    "positive": 1,
    "negative": 0,
    1: 1,
    0: 0
})

df = df.dropna()

"""TRAIN / TEST SPLIT"""

from sklearn.model_selection import train_test_split

X_train_text, X_test_text, y_train, y_test = train_test_split(
    df[text_col].values,
    df[label_col].values,
    test_size=0.2,
    random_state=42,
    stratify=df[label_col]
)

"""TOKENIZATION (WORD-LEVEL)"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(
    num_words=VOCAB_SIZE,
    oov_token="<OOV>",
    lower=True
)

tokenizer.fit_on_texts(X_train_text)

# Convert text to sequences
X_train_seq = tokenizer.texts_to_sequences(X_train_text)
X_test_seq = tokenizer.texts_to_sequences(X_test_text)

"""PADDING & MASKING"""

X_train = pad_sequences(
    X_train_seq,
    maxlen=MAX_LEN,
    padding="post",
    truncating="post"
)

X_test = pad_sequences(
    X_test_seq,
    maxlen=MAX_LEN,
    padding="post",
    truncating="post"
)

print(X_train.shape, X_test.shape)

"""LSTM MODEL"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

model = Sequential([
    Embedding(
        input_dim=VOCAB_SIZE,
        output_dim=EMBED_DIM,
        input_length=MAX_LEN,
        mask_zero=True
    ),
    LSTM(
        LSTM_UNITS,
        dropout=0.2,
        recurrent_dropout=0.2
    ),
    Dense(1, activation="sigmoid")
])

model.build(input_shape=(None, MAX_LEN))
model.summary()

"""COMPILE & TRAIN"""

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

history = model.fit(
    X_train,
    y_train,
    validation_split=0.2,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE
)

"""EVALUATION"""

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

"""TRAINING CURVES"""

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="Train")
plt.plot(history.history["val_accuracy"], label="Val")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="Train")
plt.plot(history.history["val_loss"], label="Val")
plt.title("Loss")
plt.legend()

plt.show()

"""SAVE MODEL & TOKENIZER"""

model.save("lstm_sentiment.h5")

with open("tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)

"""FINAL SANITY TEST"""

def predict_sentiment(text):
    seq = tokenizer.texts_to_sequences([text])
    pad = pad_sequences(seq, maxlen=MAX_LEN, padding="post")
    prob = model.predict(pad)[0][0]
    return prob

predict_sentiment("The movie was absolutely fantastic and emotional")

predict_sentiment("This was boring, slow, and a complete waste of time")

# ==============================
# INTERACTIVE SENTIMENT PREDICTOR
# ==============================

import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ---- CONFIG ----
MODEL_PATH = "/content/lstm_sentiment.h5"
TOKENIZER_PATH = "/content/tokenizer.pkl"
MAX_LEN = 200

# ---- LOAD MODEL ----
model = tf.keras.models.load_model(MODEL_PATH)

with open(TOKENIZER_PATH, "rb") as f:
    tokenizer = pickle.load(f)

print("‚úÖ Model and tokenizer loaded successfully.")

# ---- PREDICTION FUNCTION ----
def predict_sentiment_label(text):
    seq = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(
        seq,
        maxlen=MAX_LEN,
        padding="post",
        truncating="post"
    )
    prob = model.predict(padded, verbose=0)[0][0]
    return "POSITIVE üòä" if prob >= 0.5 else "NEGATIVE üòû"

# ---- INTERACTIVE INPUT ----
review = input("\nEnter a review to analyze sentiment:\n")

if review.strip() == "":
    print("‚ö†Ô∏è Please enter valid text.")
else:
    result = predict_sentiment_label(review)
    print("\nüéØ Sentiment Prediction:", result)

# ==============================
# INTERACTIVE SENTIMENT PREDICTOR
# ==============================

import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ---- CONFIG ----
MODEL_PATH = "/content/lstm_sentiment.h5"
TOKENIZER_PATH = "/content/tokenizer.pkl"
MAX_LEN = 200

# ---- LOAD MODEL ----
model = tf.keras.models.load_model(MODEL_PATH)

with open(TOKENIZER_PATH, "rb") as f:
    tokenizer = pickle.load(f)

print("‚úÖ Model and tokenizer loaded successfully.")

# ---- PREDICTION FUNCTION ----
def predict_sentiment_label(text):
    seq = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(
        seq,
        maxlen=MAX_LEN,
        padding="post",
        truncating="post"
    )
    prob = model.predict(padded, verbose=0)[0][0]
    return "POSITIVE üòä" if prob >= 0.5 else "NEGATIVE üòû"

# ---- INTERACTIVE INPUT ----
review = input("\nEnter a review to analyze sentiment:\n")

if review.strip() == "":
    print("‚ö†Ô∏è Please enter valid text.")
else:
    result = predict_sentiment_label(review)
    print("\nüéØ Sentiment Prediction:", result)