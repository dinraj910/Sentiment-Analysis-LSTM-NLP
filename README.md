<div align="center">

![header](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=300&section=header&text=ğŸ§ %20LSTM%20Sentiment%20Analysis&fontSize=55&fontColor=ffffff&animation=twinkling&fontAlignY=35&desc=Deep%20Learning%20%7C%20NLP%20%7C%20RNN%20%7C%20Streamlit%20Web%20App&descAlignY=55&descSize=18)

<!-- â•â•â•â•â•â•â•â•â•â•â• BADGES â•â•â•â•â•â•â•â•â•â•â• -->

[![Status](https://img.shields.io/badge/Status-Active-success?style=for-the-badge&logo=rocket&logoColor=white)](https://github.com)
[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge&logo=open-source-initiative&logoColor=white)](LICENSE)
[![Maintained](https://img.shields.io/badge/Maintained-YES-green?style=for-the-badge&logo=github&logoColor=white)](https://github.com)
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen?style=for-the-badge&logo=github&logoColor=white)](https://github.com)

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10+-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://tensorflow.org)
[![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)](https://keras.io)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org)
[![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org)

<!-- â•â•â•â•â•â•â•â•â•â•â• TYPING SVG â•â•â•â•â•â•â•â•â•â•â• -->

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=28&pause=1000&color=6A5ACD&center=true&vCenter=true&random=false&width=700&lines=ğŸš€+End-to-End+Sentiment+Analysis;ğŸ§ +Deep+Learning+with+LSTM;ğŸ“Š+Raw+Text+â†’+Production+Prediction;âš¡+Real-time+Streamlit+Web+App;ğŸ”¤+Word-Level+NLP+Pipeline" alt="Typing SVG" />
</p>

</div>

---

## ğŸ§­ **Quick Navigation**

<div align="center">

| [ğŸ¯ Overview](#-overview) | [âœ¨ Features](#-features) | [ğŸ—ï¸ Architecture](#ï¸-architecture) | [ğŸš€ Quick Start](#-quick-start) |
|:--:|:--:|:--:|:--:|
| [ğŸ“Š Demo](#-demo--screenshots) | [âš™ï¸ Configuration](#ï¸-configuration) | [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack) | [ğŸ“ˆ Performance](#-performance-metrics) |
| [ğŸ—ºï¸ Roadmap](#ï¸-roadmap) | [ğŸ¤ Contributing](#-contributing) | [ğŸ‘¨â€ğŸ’» Author](#-author) | [â­ Support](#-show-your-support) |

</div>

---

## ğŸ¯ **Overview**

<table align="center">
<tr>
<td align="center"><h3>ğŸ” What</h3></td>
<td align="center"><h3>ğŸ’¡ Why</h3></td>
</tr>
<tr>
<td align="center">
<b>Production-Ready Sentiment Classifier</b><br/>
An end-to-end LSTM neural network that processes<br/>
raw text and predicts <b>POSITIVE / NEGATIVE</b> sentiment,<br/>
deployed as an interactive Streamlit web application.
</td>
<td align="center">
<b>Industry-Standard NLP Pipeline</b><br/>
Demonstrates the complete ML workflow â€” from<br/>
data preprocessing and model training to artifact<br/>
serialization and real-time inference deployment.
</td>
</tr>
</table>

<div align="center">

```
ğŸ¯ Mission: Transform raw text into actionable sentiment insights
            using LSTM neural networks â€” trained once, deployed for real-time inference.
```

</div>

---

## âœ¨ **Features**

<div align="center">

| Feature | Status | Description |
|:--------|:------:|:------------|
| ğŸ”¤ **Word-Level Tokenization** | âœ… | Custom vocabulary (20 k words) with OOV handling via `<OOV>` token |
| ğŸ§  **LSTM Architecture** | âœ… | Many-to-One sequence modeling, 128 units with recurrent dropout |
| ğŸ“Š **Trainable Embeddings** | âœ… | 128-dimensional word vector representations learned during training |
| ğŸ¯ **Binary Classification** | âœ… | POSITIVE / NEGATIVE prediction with sigmoid threshold at 0.5 |
| ğŸŒ **Streamlit Web App** | âœ… | Real-time interactive inference with cached model loading |
| ğŸ’¾ **Model Serialization** | âœ… | Saved `.h5` model + `.pkl` tokenizer for deployment reuse |
| ğŸ“ **Padding & Masking** | âœ… | Post-padding to 200 tokens with zero-mask to protect LSTM state |
| ğŸ”’ **Config Parity** | âœ… | Training and inference use identical preprocessing parameters |
| ğŸšï¸ **Confidence Indicator** | âœ… | Qualitative certainty levels (Very High / High / Moderate / Low) |
| âš¡ **Cached Inference** | âœ… | `st.cache_resource` loads artifacts once â€” sub-second predictions |
| ğŸ’¡ **Quick Examples** | âœ… | One-click positive, negative, and nuanced test inputs |
| ğŸ“‹ **Model Card Sidebar** | âœ… | Architecture specs and pipeline steps visible at a glance |

</div>

---

## ğŸ—ï¸ **Architecture**

<div align="center">

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ§  LSTM SENTIMENT ANALYSIS PIPELINE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     ğŸ“„ Raw Text Input
          â”‚
          â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ”¤  TOKENIZATION LAYER     â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  Keras Tokenizer             â”‚
     â”‚  Vocabulary : 20,000 words   â”‚
     â”‚  OOV Token  : <OOV>          â”‚
     â”‚  Lowercased : True           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  integer sequences
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ“  PADDING & MASKING      â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  Max Length  : 200 tokens    â”‚
     â”‚  Padding     : post          â”‚
     â”‚  Truncating  : post          â”‚
     â”‚  Mask Zero   : True          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  fixed-shape tensor
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ¯  EMBEDDING LAYER        â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  Input Dim   : 20,000        â”‚
     â”‚  Output Dim  : 128           â”‚
     â”‚  Trainable   : True          â”‚
     â”‚  Mask Zero   : True          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  (batch, 200, 128)
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ§   LSTM LAYER             â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  Units       : 128           â”‚
     â”‚  Type        : Many-to-One   â”‚
     â”‚  Dropout     : 0.2           â”‚
     â”‚  Rec Dropout : 0.2           â”‚
     â”‚  Return Seq  : False         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  (batch, 128)
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ²  DENSE + SIGMOID        â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  Units       : 1             â”‚
     â”‚  Activation  : Sigmoid       â”‚
     â”‚  Threshold   : 0.5           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ğŸ“Š  OUTPUT                  â”‚
     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
     â”‚  â‰¥ 0.5 â†’ ğŸ˜Š POSITIVE        â”‚
     â”‚  < 0.5 â†’ ğŸ˜ NEGATIVE        â”‚
     â”‚  + Confidence Level          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

---

<details>
<summary><h2>ğŸ”¬ <b>Technical Deep Dive</b></h2></summary>

### ğŸ§¬ **Model Specifications**

| Component | Configuration | Rationale |
|:----------|:--------------|:----------|
| **Vocabulary Size** | 20,000 tokens | Balances lexical coverage vs. embedding matrix size |
| **Sequence Length** | 200 tokens | Captures most review content without over-padding |
| **Embedding Dim** | 128 dimensions | Adequate semantic representation for sentiment |
| **LSTM Units** | 128 cells | Sufficient memory capacity for sequence dependencies |
| **Dropout** | 0.2 + 0.2 recurrent | Regularization against overfitting |
| **Activation** | Sigmoid | Binary classification output âˆˆ [0, 1] |
| **Masking** | `mask_zero=True` | Prevents padded zeros from corrupting LSTM hidden state |

### ğŸ”§ **Training Configuration**

```python
# â”€â”€ Reproducibility â”€â”€
tf.random.set_seed(42)
np.random.seed(42)

# â”€â”€ Hyperparameters â”€â”€
VOCAB_SIZE  = 20000
MAX_LEN     = 200
EMBED_DIM   = 128
LSTM_UNITS  = 128
BATCH_SIZE  = 32
EPOCHS      = 5

# â”€â”€ Optimizer & Loss â”€â”€
optimizer   = "adam"          # Adam (lr = 0.001 default)
loss        = "binary_crossentropy"
metrics     = ["accuracy"]
val_split   = 0.2            # 20% of training data
```

### ğŸ“Š **Data Pipeline**

```
CSV (240k records)
  â”‚
  â”œâ”€ 1. Column inference         â†’ detect text & label columns
  â”œâ”€ 2. Label normalization      â†’ map to binary {0, 1}
  â”œâ”€ 3. Stratified train/test    â†’ 80/20 split (random_state=42)
  â”œâ”€ 4. Word-level tokenization  â†’ Keras Tokenizer (fit on train only)
  â”œâ”€ 5. Sequence encoding        â†’ texts_to_sequences()
  â”œâ”€ 6. Post-padding / truncate  â†’ fixed 200-token tensors
  â””â”€ 7. Batched training         â†’ 32 samples/batch Ã— 5 epochs
```

### ğŸ¯ **Design Decisions**

| Decision | Why It Matters |
|:--|:--|
| Tokenizer fit on training data only | Prevents data leakage from test set vocabulary |
| Post-padding (not pre-padding) | With `mask_zero=True`, padding position is irrelevant â€” mask handles it |
| OOV token `<OOV>` | Gracefully handles unseen words at inference without crashes |
| No pre-trained embeddings | Demonstrates learned representations; keeps dependencies minimal |
| Single LSTM (no Bi-LSTM) | Sufficient for binary sentiment; prioritizes clarity over complexity |
| Pickle for tokenizer | Preserves word index + config exactly as fitted; standard practice |

</details>

---

## ğŸ“‚ **Project Structure**

```
ğŸ¯ sentiment-analysis-lstm/
â”‚
â”œâ”€â”€ ğŸŒ app/
â”‚   â”œâ”€â”€ app.py                         # ğŸš€ Streamlit inference application
â”‚   â””â”€â”€ requirements.txt               # ğŸ“¦ Runtime dependencies (minimal)
â”‚
â”œâ”€â”€ ğŸ¤– model/
â”‚   â”œâ”€â”€ lstm_sentiment.h5              # ğŸ’¾ Trained LSTM model (Keras HDF5)
â”‚   â””â”€â”€ tokenizer.pkl                  # ğŸ”¤ Fitted Keras Tokenizer (pickle)
â”‚
â”œâ”€â”€ ğŸ““ notebook/
â”‚   â”œâ”€â”€ sentiment_lstm_kaggle.ipynb    # ğŸ”¬ Training & evaluation notebook
â”‚   â””â”€â”€ sentiment_lstm_kaggle.py       # ğŸ“„ Exported Python script
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ sentiment_data.csv             # ğŸ“‹ Kaggle dataset (~240k records)
â”‚
â”œâ”€â”€ ğŸ“ README.md                       # ğŸ“– This file
â””â”€â”€ ğŸš« .gitignore                      # ğŸ”’ Git ignore rules
```

---

## ğŸš€ **Quick Start**

### ğŸ“‹ **Prerequisites**

<div align="center">

| Requirement | Version | Check Command |
|:------------|:--------|:--------------|
| **ğŸ Python** | 3.8+ | `python --version` |
| **ğŸ“¦ pip** | Latest | `pip --version` |
| **ğŸ”— Git** | Latest | `git --version` |

</div>

### âš¡ **Installation Steps**

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/dinraj910/sentiment-analysis-lstm.git
cd sentiment-analysis-lstm

# 2ï¸âƒ£ Install dependencies
pip install -r app/requirements.txt

# 3ï¸âƒ£ Launch the Streamlit app
streamlit run app/app.py

# 4ï¸âƒ£ Open in browser
# ğŸŒ Local URL: http://localhost:8501
```

### ğŸ”§ **Development Setup**

```bash
# ğŸ““ Open the training notebook
cd notebook
jupyter notebook sentiment_lstm_kaggle.ipynb
```

---

## ğŸ“Š **Demo & Screenshots**

<div align="center">

### ğŸ¬ **Live Prediction Examples**

| Input Text | Prediction | Confidence |
|:-----------|:-----------|:-----------|
| *"This product is amazing and exceeded all my expectations!"* | ğŸ˜Š **POSITIVE** | Very High |
| *"Terrible quality. It broke after one day."* | ğŸ˜ **NEGATIVE** | Very High |
| *"The camera is great but the battery life is disappointing."* | ğŸ¤” **Context-dependent** | Moderate |

### ğŸ’» **Web Interface**

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  LSTM Sentiment Analyzer                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                     â”‚
â”‚  ğŸ“ Enter text to analyze:                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ The movie was absolutely incredible and      â”‚    â”‚
â”‚  â”‚ the acting was phenomenal...                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                     â”‚
â”‚          [ğŸ” Analyze Sentiment]                     â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ˜Š POSITIVE                                 â”‚    â”‚
â”‚  â”‚ Confidence: Very High                        â”‚    â”‚
â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  Very High      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                     â”‚
â”‚  â”€â”€ ğŸ’¡ Quick Examples â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  [ Positive ]  [ Negative ]  [ Nuanced ]           â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€ ğŸ§  Model Card (Sidebar) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Architecture : LSTM (Many-to-One)           â”‚    â”‚
â”‚  â”‚ Embedding    : 128-d, trainable             â”‚    â”‚
â”‚  â”‚ LSTM Units   : 128                          â”‚    â”‚
â”‚  â”‚ Vocab Size   : 20,000                       â”‚    â”‚
â”‚  â”‚ Seq Length    : 200 (post-padded)            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

---

## âš™ï¸ **Configuration**

<div align="center">

### ğŸ”§ **App Configuration (must match training)**

| Variable | Value | Description |
|:---------|:------|:------------|
| `MODEL_PATH` | `model/lstm_sentiment.h5` | Path to trained Keras model |
| `TOKENIZER_PATH` | `model/tokenizer.pkl` | Path to fitted tokenizer |
| `MAX_LEN` | `200` | Maximum sequence length (post-padded) |
| `THRESHOLD` | `0.5` | Sigmoid classification threshold |

### ğŸ§  **Training-Time Configuration (locked)**

| Variable | Value | Description |
|:---------|:------|:------------|
| `VOCAB_SIZE` | `20,000` | Maximum vocabulary size |
| `EMBED_DIM` | `128` | Embedding vector dimensions |
| `LSTM_UNITS` | `128` | LSTM hidden state size |
| `BATCH_SIZE` | `32` | Training mini-batch size |
| `EPOCHS` | `5` | Training iterations |

### ğŸ“¦ **Runtime Dependencies**

```txt
tensorflow>=2.10.0     # Model loading & inference
streamlit>=1.28.0      # Web application framework
numpy>=1.21.0          # Numerical operations
```

> âš¡ Training-only libraries (pandas, sklearn, matplotlib) are intentionally excluded from runtime.

</div>

---

## ğŸ› ï¸ **Tech Stack**

<div align="center">

### ğŸ§  **Core Technologies**

| Category | Technologies |
|:---------|:-------------|
| **ğŸ¤– Deep Learning** | ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat-square&logo=tensorflow&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-D00000?style=flat-square&logo=keras&logoColor=white) |
| **ğŸ Language** | ![Python](https://img.shields.io/badge/Python_3.8+-3776AB?style=flat-square&logo=python&logoColor=white) |
| **ğŸŒ Deployment** | ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white) |
| **ğŸ“Š Data & NLP** | ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white) |
| **ğŸ“ˆ Visualization** | ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat-square&logo=python&logoColor=white) |
| **ğŸ’¾ Serialization** | HDF5 (model) Â· Pickle (tokenizer) |
| **ğŸ”§ Tools** | ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white) ![Git](https://img.shields.io/badge/Git-F05032?style=flat-square&logo=git&logoColor=white) ![Google Colab](https://img.shields.io/badge/Colab-F9AB00?style=flat-square&logo=googlecolab&logoColor=white) |

</div>

---

## ğŸ“ˆ **Performance Metrics**

<div align="center">

### ğŸ¯ **Model Training Summary**

| Parameter | Value |
|:----------|:------|
| **ğŸ“‹ Dataset** | ~240,000 text records (binary: positive / negative) |
| **âœ‚ï¸ Train / Test Split** | 80 / 20 (stratified, `random_state=42`) |
| **âš™ï¸ Optimizer** | Adam (lr = 0.001) |
| **ğŸ“‰ Loss Function** | Binary cross-entropy |
| **ğŸ”„ Epochs** | 5 |
| **ğŸ“¦ Batch Size** | 32 |
| **ğŸ“Š Validation** | 20% of training set |

### âš¡ **Inference Performance**

| Operation | Time | Notes |
|:----------|:-----|:------|
| **ğŸ¤– Model Loading** | ~2s (first run) | Cached via `st.cache_resource` |
| **ğŸ”¤ Text Preprocessing** | < 10ms | Tokenize + pad |
| **ğŸ§  Forward Pass** | < 50ms | Single sample prediction |
| **ğŸŒ Total Response** | < 100ms | After initial load |

> ğŸ““ Training curves and detailed evaluation are available in `notebook/sentiment_lstm_kaggle.ipynb`.

</div>

---

## ğŸ—ºï¸ **Roadmap**

```mermaid
graph TD
    A[âœ… LSTM Model Training] --> B[âœ… Artifact Serialization]
    B --> C[âœ… Streamlit Deployment]
    C --> D[ğŸ”„ Bidirectional LSTM]
    D --> E[â³ Attention Mechanism]
    E --> F[ğŸ“‹ Multi-class Sentiment]
    F --> G[ğŸ³ Docker Containerization]
    G --> H[ğŸ”„ CI/CD Pipeline]
    H --> I[â˜ï¸ Cloud Deployment]

    style A fill:#28a745,stroke:#1e7e34,color:#fff
    style B fill:#28a745,stroke:#1e7e34,color:#fff
    style C fill:#28a745,stroke:#1e7e34,color:#fff
    style D fill:#ffc107,stroke:#e0a800,color:#000
    style E fill:#ffc107,stroke:#e0a800,color:#000
    style F fill:#ffc107,stroke:#e0a800,color:#000
    style G fill:#ffc107,stroke:#e0a800,color:#000
    style H fill:#6c757d,stroke:#545b62,color:#fff
    style I fill:#6c757d,stroke:#545b62,color:#fff
```

<div align="center">

### ğŸš€ **Planned Enhancements**

| Phase | Feature | Status | Priority |
|:------|:--------|:------:|:---------|
| **Phase 1** | âœ… LSTM training + Streamlit app | âœ… Done | â€” |
| **Phase 2** | ğŸ”„ Bidirectional LSTM variant | ğŸ”„ Next | High |
| **Phase 3** | â³ Attention mechanism integration | â³ Planned | High |
| **Phase 4** | ğŸ“‹ Multi-class sentiment (pos / neu / neg) | â³ Planned | Medium |
| **Phase 5** | ğŸ³ Dockerized deployment | â³ Planned | Medium |
| **Phase 6** | ğŸ”„ CI/CD with automated testing | ğŸ’­ Backlog | Low |

</div>

---

## ğŸ’¼ **Skills Demonstrated**

<div align="center">

> *This project is designed to showcase job-relevant AI / ML engineering skills.*

| Skill Area | What This Project Proves |
|:-----------|:-------------------------|
| ğŸ§  **Sequence Modeling** | LSTM-based text classification with proper padding, masking, and trainable embeddings |
| ğŸ”¤ **NLP Pipeline Design** | End-to-end: raw text â†’ tokenization â†’ integer encoding â†’ padded tensors â†’ prediction |
| ğŸš€ **Model Deployment** | Serving a trained model via Streamlit with cached artifact loading |
| ğŸ’¾ **Artifact Management** | Serializing / deserializing model (HDF5) + tokenizer (pickle) for inference-only use |
| âš™ï¸ **Production Practices** | Config parity between training and inference, input validation, minimal runtime dependencies |
| ğŸ—ï¸ **Software Engineering** | Modular code, docstrings, type hints, session state management, clean project structure |
| ğŸ“Š **Data Engineering** | Stratified splits, label normalization, vocabulary control, reproducibility via seeds |

</div>

---

## ğŸ¤ **Contributing**

<div align="center">

Contributions are welcome! ğŸ‰

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=for-the-badge)](https://github.com/dinraj910/sentiment-analysis-lstm)

</div>

### ğŸ”§ **How to Contribute**

1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** your feature branch (`git checkout -b feature/amazing-feature`)
3. **ğŸ’¾ Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **ğŸš€ Push** to the branch (`git push origin feature/amazing-feature`)
5. **ğŸ¯ Open** a Pull Request

### ğŸ“‹ **Guidelines**

- Follow PEP 8 style conventions
- Include docstrings for new functions
- Ensure training/inference config parity is maintained
- Update documentation for significant changes

---

## ğŸ“œ **License**

<div align="center">

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge&logo=open-source-initiative&logoColor=white)](LICENSE)

</div>

---

## ğŸ‘¨â€ğŸ’» **Author**

<div align="center">

<img src="https://avatars.githubusercontent.com/u/dinraj910?v=4" width="120" style="border-radius: 50%"/>

### **Dinraj K Dinesh**

*Deep Learning Engineer Â· NLP Practitioner Â· Python Developer*

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/dinraj-k-dinesh)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/dinraj910)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:dinrajdinesh564@gmail.com)
[![Portfolio](https://img.shields.io/badge/Portfolio-FF5722?style=for-the-badge&logo=web&logoColor=white)](https://github.com/dinraj910)

</div>

---

## ğŸ™ **Acknowledgments**

<div align="center">

| | Credit |
|:--:|:--|
| ğŸ“Š | **Kaggle** â€” Sentiment analysis dataset |
| ğŸ§  | **TensorFlow / Keras** â€” Deep learning framework |
| ğŸŒ | **Streamlit** â€” Web application framework |
| ğŸ““ | **Google Colab** â€” Training environment |
| ğŸ‘¥ | **Open-source community** â€” Tools and inspiration |

</div>

---

## â­ **Show Your Support**

<div align="center">

If this project helped you, give it a â­ â€” it helps others discover it!

[![Star History Chart](https://api.star-history.com/svg?repos=dinraj910/sentiment-analysis-lstm&type=Date)](https://star-history.com/#dinraj910/sentiment-analysis-lstm&Date)

---

**ğŸš€ Built with ğŸ’œ and lots of â˜•**

*Turning raw text into sentiment, one LSTM cell at a time.*

![footer](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=120&section=footer&fontSize=20&fontColor=ffffff&animation=twinkling)

</div>
